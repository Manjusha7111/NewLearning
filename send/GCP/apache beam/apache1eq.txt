data.csv
id,name,age,city
1, John Doe ,25,
2, Jane Smith,,Paris


cleaned_data.csv
id,name,age,city
1,John Doe,25,NULL
2,Jane Smith,,Paris

__________
import apache_beam as beam
 
def run_pipeline():
 
    with beam.Pipeline() as pipeline:
    
        cleaned_data = (
            pipeline
| "Read CSV" >> beam.io.ReadFromText("/home/balathoti_manjusha/python/apache/data.csv")
| "Clean Data" >> beam.Map(clean_record)
| "Write Clean CSV" >> beam.io.WriteToText("/home/balathoti_manjusha/python/apache/cleaned_data.csv")
        )
 
def clean_record(record):
    values = record.split(",")

    # Data cleaning steps    
    values[1] = values[1].strip()  
    if values[3] == "":
        values[3] = "NULL"
    
    # Cleaning code   
    return ",".join(values)
 
if __name__ == "__main__":
    run_pipeline()




_________________________
o/p:
cleaned_data.csv will be created ,after applying transformations to data.csv
___________________________
explanation:

values = record.split(",")
#split csv file rpw string  list of values based on common delimeter ','.
eg:values["id","name","age","city"]

# removes any leadind whitespaces   eq:"   john"  -"john"
values[1] = values[1].strip() 

#if col 3 have any no value it replaces with null 
    if values[3] == "":
        values[3] = "NULL"



return ",".join(values)
#join the cleasned list of values back into a csv row string.

